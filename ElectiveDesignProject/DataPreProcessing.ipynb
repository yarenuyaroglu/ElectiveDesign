{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Data Pre-Processing**"
      ],
      "metadata": {
        "id": "7U7MHdO6kW5T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JR40FQfOgxYW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD0Ozf_Fg1Tx",
        "outputId": "e8b5b372-6a37-42bf-d828-b70318ba70ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_path = \"/content/drive/MyDrive/SignLanguage/TurkishSignLanguageYoloV8/train/images\"\n",
        "train_labels_path = \"/content/drive/MyDrive/SignLanguage/TurkishSignLanguageYoloV8/train/labels\""
      ],
      "metadata": {
        "id": "Wd8lUij1g6x5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalizing the image dimensions:RESIZE And NORMALIZE\n",
        "\n",
        "def resize_and_normalize_images(image_folder, target_size=(640, 640)):\n",
        "    resized_folder = f\"{image_folder}_resized\"\n",
        "    os.makedirs(resized_folder, exist_ok=True)\n",
        "\n",
        "    for img_path in tqdm(glob(os.path.join(image_folder, \"*.jpg\"))):\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        resized_img = cv2.resize(img, target_size)\n",
        "\n",
        "        normalized_img = resized_img / 255.0\n",
        "\n",
        "\n",
        "        new_img_path = os.path.join(resized_folder, os.path.basename(img_path))\n",
        "        cv2.imwrite(new_img_path, (normalized_img * 255).astype(np.uint8))\n",
        "\n",
        "    return resized_folder"
      ],
      "metadata": {
        "id": "1AZ9G1R6hNkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def augment_images(image_folder, save_to_folder, augment_count=3):\n",
        "    os.makedirs(save_to_folder, exist_ok=True)\n",
        "    #Data Generator\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=30,  #Rotation Range\n",
        "        width_shift_range=0.2,  #Width Shift\n",
        "        height_shift_range=0.2,  #Height Shift\n",
        "        shear_range=0.2,  #Shear Range\n",
        "        zoom_range=0.2,  #Zoom Range\n",
        "        horizontal_flip=True,  #Horizontal\n",
        "        fill_mode='nearest'  #Fill Mode\n",
        "    )\n",
        "\n",
        "    for img_path in tqdm(glob(os.path.join(image_folder, \"*.jpg\"))):\n",
        "        img = cv2.imread(img_path)\n",
        "        # make the appropriate shape\n",
        "        img = img.reshape((1,) + img.shape)\n",
        "        i = 0\n",
        "        # Creating a certain number of augmented versions for each image\n",
        "        for batch in datagen.flow(img, batch_size=1, save_to_dir=save_to_folder, save_prefix='aug', save_format='jpg'):\n",
        "            i += 1\n",
        "            if i >= augment_count:\n",
        "                break"
      ],
      "metadata": {
        "id": "Vcg4axdCh1L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying Resize and Normalize Function\n",
        "resized_images_folder = resize_and_normalize_images(train_images_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1CT7kDEi8xm",
        "outputId": "bdc510ff-540e-4706-a3c0-108fc9b6f650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20043/20043 [15:12<00:00, 21.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying Augmentation Function\n",
        "augment_save_folder = \"/content/drive/MyDrive/SignLanguage/TurkishSignLanguageYoloV8/train/augmented_images\"\n",
        "augment_images(resized_images_folder, augment_save_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_IBRiOgjeJj",
        "outputId": "90ded20e-0da0-4bba-c217-73686795651e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20043/20043 [1:47:52<00:00,  3.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def denoise_images(image_folder):\n",
        "    denoised_folder = f\"{image_folder}_denoised\"\n",
        "    os.makedirs(denoised_folder, exist_ok=True)\n",
        "\n",
        "    for img_path in tqdm(glob(os.path.join(image_folder, \"*.jpg\"))):\n",
        "        img = cv2.imread(img_path)\n",
        "        denoised_img = cv2.medianBlur(img, 3)  # Median Blur kullanarak gürültü giderme\n",
        "        new_img_path = os.path.join(denoised_folder, os.path.basename(img_path))\n",
        "        cv2.imwrite(new_img_path, denoised_img)\n",
        "\n",
        "    return denoised_folder"
      ],
      "metadata": {
        "id": "l0uQQPhUJ0GP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combined Preprocessing Function (Denoise, Histogram Equalization, )\n",
        "def combined_preprocessing(image_folder, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for img_path in tqdm(glob(os.path.join(image_folder, \"*.jpg\"))):\n",
        "        # Read Image\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Step 1: Denoise Image\n",
        "        denoised_img = cv2.medianBlur(img, 3)\n",
        "\n",
        "        # Step 2: Histogram Equalization (only for grayscale images)\n",
        "        if len(denoised_img.shape) == 2:  # Grayscale\n",
        "            equalized_img = cv2.equalizeHist(denoised_img)\n",
        "        else:  # Color Image\n",
        "            img_y_cr_cb = cv2.cvtColor(denoised_img, cv2.COLOR_BGR2YCrCb)\n",
        "            y, cr, cb = cv2.split(img_y_cr_cb)\n",
        "            y_eq = cv2.equalizeHist(y)\n",
        "            equalized_img = cv2.merge((y_eq, cr, cb))\n",
        "            equalized_img = cv2.cvtColor(equalized_img, cv2.COLOR_YCrCb2BGR)\n",
        "\n",
        "        # Save Preprocessed Image\n",
        "        new_img_path = os.path.join(output_folder, os.path.basename(img_path))\n",
        "        cv2.imwrite(new_img_path, equalized_img)\n"
      ],
      "metadata": {
        "id": "9LJ88S4YMWxg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augment_save_folder = \"/content/drive/MyDrive/SignLanguage/TurkishSignLanguageYoloV8/train/augmented_images\"\n",
        "final_output_path = \"/content/drive/MyDrive/SignLanguage/TurkishSignLanguageYoloV8/train/final_processed_images\""
      ],
      "metadata": {
        "id": "3D8pbTN3NJb8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Combined Preprocessing on Augmented Images\n",
        "combined_preprocessing(augment_save_folder, final_output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e__w76GxMfkr",
        "outputId": "5f748f1d-49ed-45f0-fdf3-9de5b4704af9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9968/9968 [08:58<00:00, 18.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_labels_path = \"/content/drive/MyDrive/SignLanguage/TurkishSignLanguageYoloV8/train/processed_labels\""
      ],
      "metadata": {
        "id": "TmouracXOAlf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Preprocessing Function\n",
        "def preprocess_labels(label_folder, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for label_path in tqdm(glob(os.path.join(label_folder, \"*.txt\"))):\n",
        "        with open(label_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        processed_lines = []\n",
        "        for line in lines:\n",
        "            # Split the bounding box information\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) == 9:\n",
        "                class_id, x_center, y_center, width, height, x_min, y_min, x_max, y_max = parts\n",
        "                # Convert to float for potential rescaling (if needed)\n",
        "                x_center = float(x_center)\n",
        "                y_center = float(y_center)\n",
        "                width = float(width)\n",
        "                height = float(height)\n",
        "                x_min = float(x_min)\n",
        "                y_min = float(y_min)\n",
        "                x_max = float(x_max)\n",
        "                y_max = float(y_max)\n",
        "\n",
        "                # Here you could add any preprocessing steps for labels, such as scaling or adjustments\n",
        "                # For now, we will keep them the same\n",
        "\n",
        "                processed_lines.append(f\"{class_id} {x_center} {y_center} {width} {height} {x_min} {y_min} {x_max} {y_max}\\n\")\n",
        "\n",
        "        # Save processed label\n",
        "        new_label_path = os.path.join(output_folder, os.path.basename(label_path))\n",
        "        with open(new_label_path, 'w') as file:\n",
        "            file.writelines(processed_lines)"
      ],
      "metadata": {
        "id": "V8L9BcifNxUP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Label Preprocessing on Original Labels\n",
        "preprocess_labels(train_labels_path, processed_labels_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3CXeLdrN3aZ",
        "outputId": "0a22ef9a-42d0-419c-9792-4a7c734f64c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20040/20040 [1:41:06<00:00,  3.30it/s]\n"
          ]
        }
      ]
    }
  ]
}